#!/usr/bin/env python
"""
ComfyUI Wan2.1 æ¨ç†è„šæœ¬ - ä½¿ç”¨ API æ ¼å¼ workflow
ç›´æ¥ä½¿ç”¨ ComfyUI å¯¼å‡ºçš„ API æ ¼å¼ JSONï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨è§£æ workflow

Workflow èŠ‚ç‚¹æ˜ å°„:
- èŠ‚ç‚¹ 58 (LoadImage) â† å›¾åº“é€‰æ‹©çš„å›¾ç‰‡
- èŠ‚ç‚¹ 71 (WanVideoLoraSelect) â† é€‰æ‹©çš„ LoRA æ¨¡å‹
- èŠ‚ç‚¹ 81 (TextToLowercase) â† è§¦å‘è¯è¾“å…¥
- èŠ‚ç‚¹ 30 (VHS_VideoCombine) â†’ è¾“å‡ºç»“æœ
"""
import os
import sys
import json
import time
import argparse
import requests
import shutil
import hashlib
from pathlib import Path

# è·¯å¾„é…ç½®
COMFYUI_URL = "http://127.0.0.1:8188"
COMFYUI_INPUT_DIR = Path("/home/disk2/comfyui/input")
COMFYUI_OUTPUT_DIR = Path("/home/disk2/comfyui/output")
COMFYUI_LORAS_DIR = Path("/home/disk2/comfyui/models/loras")
WORKFLOW_PATH = Path("/home/disk2/comfyui/user/default/workflows/wanvideo_2_1_14B_I2V_odeo.json")

# èŠ‚ç‚¹ ID æ˜ å°„ï¼ˆå¯¹åº” wanvideo_2_1_14B_I2V_odeo.jsonï¼‰
NODE_LOAD_IMAGE = "58"        # LoadImage - è¾“å…¥å›¾ç‰‡
NODE_LORA_SELECT = "71"       # WanVideoLoraSelect - ç”¨æˆ· LoRA
NODE_TRIGGER_WORD = "81"      # TextToLowercase - è§¦å‘è¯
NODE_OUTPUT_VIDEO = "30"      # VHS_VideoCombine - è¾“å‡ºè§†é¢‘


def parse_args():
    parser = argparse.ArgumentParser(description='ComfyUI Wan2.1 Video Inference')
    
    # å¿…éœ€å‚æ•°
    parser.add_argument('--lora_path', type=str, required=True, 
                        help='Path to LoRA file (maps to Node 71)')
    parser.add_argument('--trigger_word', type=str, required=True, 
                        help='Trigger word for prompt (maps to Node 81)')
    parser.add_argument('--image_path', type=str, required=True, 
                        help='Input image path (maps to Node 58)')
    parser.add_argument('--output', type=str, required=True, 
                        help='Output video path (from Node 30)')
    
    # å¯é€‰å‚æ•°
    parser.add_argument('--lora_strength', type=float, default=1.0, 
                        help='LoRA strength (0-1)')
    parser.add_argument('--gpu', type=int, default=4, 
                        help='GPU ID (4-7)')
    parser.add_argument('--seed', type=int, default=-1, 
                        help='Random seed (-1 for random)')
    parser.add_argument('--use_auto_caption', action='store_true', default=True,
                        help='Use QwenVL to auto-caption image (default: True)')
    parser.add_argument('--no_auto_caption', action='store_true',
                        help='Disable auto-caption, use trigger word only')
    parser.add_argument('--num_frames', type=int, default=81,
                        help='Number of frames to generate')
    parser.add_argument('--steps', type=int, default=4,
                        help='Number of sampling steps')
    parser.add_argument('--cfg', type=float, default=1.0,
                        help='CFG scale')
    
    return parser.parse_args()


def get_lora_relative_path(lora_path):
    """å°† LoRA ç»å¯¹è·¯å¾„è½¬æ¢ä¸º ComfyUI loras ç›®å½•çš„ç›¸å¯¹è·¯å¾„"""
    lora_path = Path(lora_path)
    
    if not lora_path.exists():
        raise FileNotFoundError(f"LoRA æ–‡ä»¶ä¸å­˜åœ¨: {lora_path}")
    
    # åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„ç¬¦å·é“¾æ¥åç§°
    path_hash = hashlib.md5(str(lora_path).encode()).hexdigest()[:8]
    lora_filename = f"infer_{path_hash}_{lora_path.name}"
    
    dest_path = COMFYUI_LORAS_DIR / lora_filename
    
    # åˆ›å»ºæˆ–æ›´æ–°ç¬¦å·é“¾æ¥
    if dest_path.exists() or dest_path.is_symlink():
        if dest_path.is_symlink():
            current_target = os.readlink(dest_path)
            if current_target != str(lora_path):
                os.remove(dest_path)
                os.symlink(str(lora_path), str(dest_path))
    else:
        os.symlink(str(lora_path), str(dest_path))
    
    print(f"[Inference] LoRA ç¬¦å·é“¾æ¥: {lora_filename}")
    return lora_filename


def prepare_image(image_path):
    """å°†å›¾ç‰‡å¤åˆ¶åˆ° ComfyUI input ç›®å½•"""
    img_src = Path(image_path)
    if not img_src.exists():
        raise FileNotFoundError(f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
    
    img_dest = COMFYUI_INPUT_DIR / img_src.name
    if not img_dest.exists() or img_src.stat().st_mtime > img_dest.stat().st_mtime:
        shutil.copy2(img_src, img_dest)
    
    return img_src.name


def create_api_prompt(lora_name, trigger_word, image_name, lora_strength=1.0, seed=-1, 
                       use_auto_caption=True, num_frames=81, steps=4, cfg=1.0):
    """
    åˆ›å»ºå®Œæ•´çš„ ComfyUI API prompt
    
    Workflow èŠ‚ç‚¹æ˜ å°„:
    - èŠ‚ç‚¹ 58 (LoadImage) â† image_name (å›¾åº“é€‰æ‹©çš„å›¾ç‰‡)
    - èŠ‚ç‚¹ 71 (WanVideoLoraSelect) â† lora_name, lora_strength (é€‰æ‹©çš„ LoRA æ¨¡å‹)
    - èŠ‚ç‚¹ 81 (TextToLowercase) â† trigger_word (è§¦å‘è¯è¾“å…¥)
    - èŠ‚ç‚¹ 30 (VHS_VideoCombine) â†’ è¾“å‡ºç»“æœ
    
    Args:
        lora_name: LoRA æ–‡ä»¶åï¼ˆåœ¨ ComfyUI loras ç›®å½•ä¸­ï¼‰
        trigger_word: è§¦å‘è¯
        image_name: è¾“å…¥å›¾ç‰‡æ–‡ä»¶åï¼ˆåœ¨ ComfyUI input ç›®å½•ä¸­ï¼‰
        lora_strength: LoRA å¼ºåº¦ (0-1)
        seed: éšæœºç§å­ï¼Œ-1 è¡¨ç¤ºéšæœº
        use_auto_caption: æ˜¯å¦ä½¿ç”¨ QwenVL è‡ªåŠ¨æè¿°å›¾ç‰‡ï¼ˆä¸è§¦å‘è¯æ‹¼æ¥ï¼‰
        num_frames: ç”Ÿæˆå¸§æ•°
        steps: é‡‡æ ·æ­¥æ•°
        cfg: CFG scale
    """
    actual_seed = seed if seed > 0 else int(time.time()) % 2147483647
    
    # åŸºç¡€ API prompt
    api_prompt = {
        # === æ–‡æœ¬å¤„ç†éƒ¨åˆ† ===
        
        # Node 81: è§¦å‘è¯è½¬å°å†™ï¼ˆå¯¹åº”å·¥ä½œæµä¸­çš„ TextToLowercaseï¼‰
        "81": {
            "class_type": "TextToLowercase",
            "inputs": {
                "texts": trigger_word
            }
        },
        
        # Node 11: T5 æ–‡æœ¬ç¼–ç å™¨
        "11": {
            "class_type": "LoadWanVideoT5TextEncoder",
            "inputs": {
                "model_name": "models_t5_umt5-xxl-enc-bf16.pth",
                "precision": "bf16",
                "load_device": "offload_device",
                "quantization": "disabled"
            }
        },
        
        # === å›¾åƒåŠ è½½éƒ¨åˆ† ===
        
        # Node 58: å›¾ç‰‡åŠ è½½ï¼ˆå¯¹åº”å·¥ä½œæµä¸­çš„ LoadImageï¼‰
        "58": {
            "class_type": "LoadImage",
            "inputs": {
                "image": image_name
            }
        },
        
        # Node 73: å›¾åƒç¼©æ”¾
        "73": {
            "class_type": "WanVideoImageResizeToClosest",
            "inputs": {
                "image": ["58", 0],
                "generation_width": 832,
                "generation_height": 480,
                "aspect_ratio_preservation": "keep_input"
            }
        },
        
        # === CLIP Vision éƒ¨åˆ† ===
        
        # Node 59: CLIP Vision åŠ è½½å™¨
        "59": {
            "class_type": "CLIPVisionLoader",
            "inputs": {
                "clip_name": "open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors"
            }
        },
        
        # Node 65: CLIP Vision ç¼–ç 
        "65": {
            "class_type": "WanVideoClipVisionEncode",
            "inputs": {
                "clip_vision": ["59", 0],
                "image_1": ["73", 0],
                "strength_1": 1,
                "strength_2": 1,
                "crop": "center",
                "combine_embeds": "average",
                "force_offload": True,
                "tiles": 0,
                "ratio": 0.2
            }
        },
        
        # === VAE éƒ¨åˆ† ===
        
        # Node 38: VAE åŠ è½½å™¨
        "38": {
            "class_type": "WanVideoVAELoader",
            "inputs": {
                "model_name": "Wan2_1_VAE_bf16.safetensors",
                "precision": "bf16",
                "use_cpu_cache": False,
                "verbose": False
            }
        },
        
        # Node 63: å›¾åƒåˆ°è§†é¢‘ç¼–ç 
        "63": {
            "class_type": "WanVideoImageToVideoEncode",
            "inputs": {
                "vae": ["38", 0],
                "clip_embeds": ["65", 0],
                "start_image": ["73", 0],
                "width": ["73", 1],
                "height": ["73", 2],
                "num_frames": num_frames,
                "noise_aug_strength": 0.03,
                "start_latent_strength": 1,
                "end_latent_strength": 1,
                "force_offload": True,
                "fun_or_fl2v_model": False,
                "tiled_vae": False,
                "augment_empty_frames": 0
            }
        },
        
        # === LoRA éƒ¨åˆ† ===
        
        # Node 71: ç”¨æˆ· LoRAï¼ˆå¯¹åº”å·¥ä½œæµä¸­çš„ WanVideoLoraSelectï¼‰
        "71": {
            "class_type": "WanVideoLoraSelect",
            "inputs": {
                "lora": lora_name,
                "strength": lora_strength,
                "low_mem_load": False
            }
        },
        
        # Node 69: ç¬¬äºŒä¸ª LoRA (distill LoRA for faster inference)
        "69": {
            "class_type": "WanVideoLoraSelect",
            "inputs": {
                "prev_lora": ["71", 0],
                "lora": "Wan21_I2V_14B_lightx2v_cfg_step_distill_lora_rank64.safetensors",
                "strength": 1,
                "low_mem_load": False
            }
        },
        
        # === æ¨¡å‹éƒ¨åˆ† ===
        
        # Node 22: æ¨¡å‹åŠ è½½å™¨
        "22": {
            "class_type": "WanVideoModelLoader",
            "inputs": {
                "lora": ["69", 0],
                "model": "Wan2_1-I2V-14B-480P_fp8_e4m3fn.safetensors",
                "base_precision": "fp16",
                "quantization": "fp8_e4m3fn",
                "load_device": "offload_device",
                "attention_mode": "sdpa",
                "rms_norm_function": "default"
            }
        },
        
        # Node 39: Block Swap é…ç½®
        "39": {
            "class_type": "WanVideoBlockSwap",
            "inputs": {
                "blocks_to_swap": 10,
                "offload_img_emb": False,
                "offload_txt_emb": False,
                "use_non_blocking": True,
                "vace_blocks_to_swap": 0,
                "prefetch_blocks": 0,
                "block_swap_debug": False
            }
        },
        
        # Node 70: è®¾ç½® Block Swap
        "70": {
            "class_type": "WanVideoSetBlockSwap",
            "inputs": {
                "model": ["22", 0],
                "block_swap_args": ["39", 0]
            }
        },
        
        # === é‡‡æ ·éƒ¨åˆ† ===
        
        # Node 27: é‡‡æ ·å™¨
        "27": {
            "class_type": "WanVideoSampler",
            "inputs": {
                "model": ["70", 0],
                "image_embeds": ["63", 0],
                "text_embeds": ["16", 0],
                "steps": steps,
                "cfg": cfg,
                "shift": 5,
                "seed": actual_seed,
                "scheduler": "dpm++_sde",
                "force_offload": True,
                "riflex_freq_index": 0,
                "denoise_strength": 1,
                "batched_cfg": "",
                "rope_function": "comfy",
                "start_step": 0,
                "end_step": -1,
                "add_noise_to_samples": False
            }
        },
        
        # === è§£ç å’Œè¾“å‡ºéƒ¨åˆ† ===
        
        # Node 28: è§£ç å™¨
        "28": {
            "class_type": "WanVideoDecode",
            "inputs": {
                "vae": ["38", 0],
                "samples": ["27", 0],
                "enable_vae_tiling": False,
                "tile_x": 272,
                "tile_y": 272,
                "tile_stride_x": 144,
                "tile_stride_y": 128,
                "normalization": "default"
            }
        },
        
        # Node 72: RIFE å¸§æ’å€¼
        "72": {
            "class_type": "RIFE VFI",
            "inputs": {
                "frames": ["28", 0],
                "ckpt_name": "rife47.pth",
                "clear_cache_after_n_frames": 10,
                "multiplier": 2,
                "fast_mode": True,
                "ensemble": True,
                "scale_factor": 1
            }
        },
        
        # Node 30: è§†é¢‘è¾“å‡ºï¼ˆå¯¹åº”å·¥ä½œæµä¸­çš„ VHS_VideoCombineï¼‰
        "30": {
            "class_type": "VHS_VideoCombine",
            "inputs": {
                "images": ["72", 0],
                "frame_rate": 32,
                "loop_count": 0,
                "filename_prefix": "WanVideoWrapper_I2V",
                "format": "video/h264-mp4",
                "pix_fmt": "yuv420p",
                "crf": 19,
                "save_metadata": True,
                "trim_to_audio": False,
                "pingpong": False,
                "save_output": True
            }
        }
    }
    
    # æ ¹æ®æ˜¯å¦ä½¿ç”¨è‡ªåŠ¨æè¿°æ¥é…ç½®æ–‡æœ¬ç¼–ç 
    if use_auto_caption:
        # ä½¿ç”¨ QwenVL è‡ªåŠ¨æè¿° + è§¦å‘è¯æ‹¼æ¥
        # Node 77: QwenVL å›¾ç‰‡æè¿°
        api_prompt["77"] = {
            "class_type": "AILab_QwenVL",
            "inputs": {
                "image": ["58", 0],
                "model_name": "Qwen3-VL-8B-Instruct",
                "quantization": "None (FP16)",
                "attention_mode": "auto",
                "preset_prompt": "ğŸ–¼ï¸ Detailed Description",
                "custom_prompt": "ä½ æ˜¯ä¸€åå›¾åƒåæ¨æç¤ºè¯ä¸“å®¶ï¼šæè¿°äººç‰©çš„å¤–è²Œã€å‘å‹ã€èº«æã€ç€è£…ï¼Œä»¥åŠèƒŒæ™¯ã€‚\n- ä¸è¦æè¿°äººç‰©çš„å§¿åŠ¿ã€åŠ¨ä½œ\n- ä¸è¦æå†™æ‰‹æ‹¿ç‰©å“\nè¾“å‡ºè§„åˆ™ï¼šä»…è¾“å‡ºè‹±æ–‡ã€å•æ®µã€â‰¤500 charactersï¼Œä¸è¦ä»»ä½•è§£é‡Š/æ ‡é¢˜/åˆ—è¡¨/JSON/å‰ç¼€ï¼Œä¸è¦æœ‰ä»»ä½•æè¿°ä»¥å¤–çš„åºŸè¯ã€‚",
                "max_tokens": 256,
                "keep_model_loaded": True,
                "seed": actual_seed
            }
        }
        
        # Node 79: Prompt æ‹¼æ¥ï¼ˆè§¦å‘è¯ + è‡ªåŠ¨æè¿°ï¼‰
        api_prompt["79"] = {
            "class_type": "easy promptConcat",
            "inputs": {
                "prompt1": ["81", 0],  # è§¦å‘è¯ï¼ˆå°å†™ï¼‰
                "prompt2": ["77", 0],  # QwenVL æè¿°
                "separator": " "
            }
        }
        
        # Node 16: æ–‡æœ¬ç¼–ç  - ä½¿ç”¨æ‹¼æ¥åçš„ prompt
        api_prompt["16"] = {
            "class_type": "WanVideoTextEncode",
            "inputs": {
                "t5": ["11", 0],
                "model_to_offload": ["22", 0],
                "positive_prompt": ["79", 0],  # ä½¿ç”¨æ‹¼æ¥ç»“æœ
                "negative_prompt": "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
                "force_offload": True,
                "use_disk_cache": False,
                "device": "gpu"
            }
        }
    else:
        # ç›´æ¥ä½¿ç”¨è§¦å‘è¯ï¼ˆå°å†™ï¼‰- ä¸ä½¿ç”¨èŠ‚ç‚¹å¼•ç”¨ï¼Œå› ä¸º TextToLowercase è¾“å‡ºæ˜¯ list
        api_prompt["16"] = {
            "class_type": "WanVideoTextEncode",
            "inputs": {
                "t5": ["11", 0],
                "model_to_offload": ["22", 0],
                "positive_prompt": trigger_word.lower(),  # ç›´æ¥ä¼ å…¥å°å†™çš„è§¦å‘è¯å­—ç¬¦ä¸²
                "negative_prompt": "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
                "force_offload": True,
                "use_disk_cache": False,
                "device": "gpu"
            }
        }
    
    return api_prompt


def queue_prompt(prompt, client_id=None):
    """å‘ ComfyUI æäº¤ prompt"""
    p = {"prompt": prompt}
    if client_id:
        p["client_id"] = client_id
    
    data = json.dumps(p).encode('utf-8')
    response = requests.post(f"{COMFYUI_URL}/prompt", data=data, headers={'Content-Type': 'application/json'})
    
    if response.status_code != 200:
        raise Exception(f"æäº¤ä»»åŠ¡å¤±è´¥: {response.status_code} - {response.text}")
    
    return response.json()


def get_history(prompt_id):
    """è·å–ä»»åŠ¡å†å²"""
    response = requests.get(f"{COMFYUI_URL}/history/{prompt_id}")
    if response.status_code == 200:
        return response.json()
    return None


def wait_for_completion(prompt_id, timeout=1800):
    """ç­‰å¾…ä»»åŠ¡å®Œæˆ"""
    start_time = time.time()
    last_print = 0
    
    while time.time() - start_time < timeout:
        history = get_history(prompt_id)
        if history and prompt_id in history:
            return history[prompt_id]
        
        elapsed = int(time.time() - start_time)
        if elapsed - last_print >= 30:
            print(f"[Inference] ç­‰å¾…æ¨ç†å®Œæˆ... ({elapsed}s)")
            last_print = elapsed
        
        time.sleep(2)
    
    raise TimeoutError(f"ä»»åŠ¡è¶…æ—¶ ({timeout}ç§’)")


def main():
    args = parse_args()
    
    # è®¾ç½® CUDA è®¾å¤‡ (æ³¨æ„ï¼šComfyUI å¯èƒ½æœ‰è‡ªå·±çš„è®¾å¤‡ç®¡ç†)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)
    
    # ç¡®å®šæ˜¯å¦ä½¿ç”¨è‡ªåŠ¨æè¿°
    use_auto_caption = args.use_auto_caption and not args.no_auto_caption
    
    print(f"[Inference] === ComfyUI Wan2.1 æ¨ç† ===")
    print(f"[Inference] Workflow èŠ‚ç‚¹æ˜ å°„:")
    print(f"[Inference]   èŠ‚ç‚¹ 58 (LoadImage) â† {args.image_path}")
    print(f"[Inference]   èŠ‚ç‚¹ 71 (WanVideoLoraSelect) â† {args.lora_path}")
    print(f"[Inference]   èŠ‚ç‚¹ 81 (TextToLowercase) â† {args.trigger_word}")
    print(f"[Inference]   èŠ‚ç‚¹ 30 (VHS_VideoCombine) â†’ {args.output}")
    print(f"[Inference] ---")
    print(f"[Inference] LoRA å¼ºåº¦: {args.lora_strength}")
    print(f"[Inference] GPU: {args.gpu}")
    print(f"[Inference] è‡ªåŠ¨æè¿°: {'å¯ç”¨' if use_auto_caption else 'ç¦ç”¨'}")
    print(f"[Inference] å¸§æ•°: {args.num_frames}, æ­¥æ•°: {args.steps}, CFG: {args.cfg}")
    
    try:
        # æ£€æŸ¥ ComfyUI æ˜¯å¦è¿è¡Œ
        try:
            response = requests.get(f"{COMFYUI_URL}/system_stats", timeout=5)
            if response.status_code != 200:
                raise Exception("ComfyUI æœªè¿è¡Œ")
        except Exception as e:
            raise Exception(f"æ— æ³•è¿æ¥åˆ° ComfyUI ({COMFYUI_URL}): {e}")
        
        print(f"[Inference] progress: 5%")
        
        # å‡†å¤‡ LoRAï¼ˆèŠ‚ç‚¹ 71ï¼‰
        lora_name = get_lora_relative_path(args.lora_path)
        print(f"[Inference] èŠ‚ç‚¹ 71 LoRA åç§°: {lora_name}")
        print(f"[Inference] progress: 8%")
        
        # å‡†å¤‡å›¾ç‰‡ï¼ˆèŠ‚ç‚¹ 58ï¼‰
        image_name = prepare_image(args.image_path)
        print(f"[Inference] èŠ‚ç‚¹ 58 å›¾ç‰‡åç§°: {image_name}")
        print(f"[Inference] progress: 10%")
        
        # åˆ›å»º API promptï¼ˆåŒ…å«æ‰€æœ‰èŠ‚ç‚¹é…ç½®ï¼‰
        api_prompt = create_api_prompt(
            lora_name=lora_name,
            trigger_word=args.trigger_word,  # èŠ‚ç‚¹ 81
            image_name=image_name,            # èŠ‚ç‚¹ 58
            lora_strength=args.lora_strength, # èŠ‚ç‚¹ 71 å¼ºåº¦
            seed=args.seed,
            use_auto_caption=use_auto_caption,
            num_frames=args.num_frames,
            steps=args.steps,
            cfg=args.cfg
        )
        print(f"[Inference] å·²åˆ›å»º API promptï¼ˆèŠ‚ç‚¹ 81 è§¦å‘è¯: {args.trigger_word}ï¼‰")
        print(f"[Inference] progress: 15%")
        
        # ä¿å­˜ debug prompt
        debug_path = Path(args.output).parent / "debug_prompt.json"
        debug_path.parent.mkdir(parents=True, exist_ok=True)
        with open(debug_path, 'w') as f:
            json.dump(api_prompt, f, indent=2)
        print(f"[Inference] è°ƒè¯•æ–‡ä»¶: {debug_path}")
        
        # æäº¤ä»»åŠ¡
        result = queue_prompt(api_prompt)
        prompt_id = result.get('prompt_id')
        if not prompt_id:
            raise Exception(f"æäº¤ä»»åŠ¡å¤±è´¥: {result}")
        
        print(f"[Inference] å·²æäº¤ä»»åŠ¡: {prompt_id}")
        print(f"[Inference] progress: 20%")
        
        # ç­‰å¾…å®Œæˆ
        history = wait_for_completion(prompt_id)
        print(f"[Inference] progress: 90%")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if 'status' in history and history['status'].get('status_str') == 'error':
            error_msg = history['status'].get('messages', [])
            raise Exception(f"æ¨ç†æ‰§è¡Œé”™è¯¯: {error_msg}")
        
        # è·å–è¾“å‡º
        outputs = history.get('outputs', {})
        
        # èŠ‚ç‚¹ 30 æ˜¯è¾“å‡ºèŠ‚ç‚¹
        output_node = outputs.get('30', {})
        if not output_node:
            for node_id, node_out in outputs.items():
                if 'videos' in node_out or 'gifs' in node_out:
                    output_node = node_out
                    break
        
        # è·å–è§†é¢‘æ–‡ä»¶
        video_info = None
        if 'videos' in output_node:
            video_info = output_node['videos'][0] if output_node['videos'] else None
        elif 'gifs' in output_node:
            video_info = output_node['gifs'][0] if output_node['gifs'] else None
        
        if video_info:
            output_filename = video_info.get('filename')
            output_subfolder = video_info.get('subfolder', '')
            
            src_path = COMFYUI_OUTPUT_DIR / output_subfolder / output_filename if output_subfolder else COMFYUI_OUTPUT_DIR / output_filename
            
            if src_path.exists():
                output_path = Path(args.output)
                output_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(src_path, output_path)
                
                print(f"[Inference] progress: 100%")
                print(f"[Inference] âœ“ æ¨ç†å®Œæˆ: {output_path}")
                print(f"[Inference] æ–‡ä»¶å¤§å°: {output_path.stat().st_size / 1024:.1f} KB")
                return 0
        
        print(f"[Inference] âœ— æœªæ‰¾åˆ°è¾“å‡ºè§†é¢‘")
        print(f"[Inference] è¾“å‡ºå†…å®¹: {outputs}")
        return 1
        
    except Exception as e:
        print(f"[Inference] âœ— æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
